{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8ad89575",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 1. Representasi embedding sederhana dari 8 token\n",
    "# -------------------------------------------------------------\n",
    "X = np.array([\n",
    "    [ 1,  0,  1,  0, -1,  0],   # gimana\n",
    "    [ 0,  1,  0, -1,  1,  0],   # nih\n",
    "    [ 1, -1,  0,  0,  0,  1],   # apa\n",
    "    [ 0,  0, -1,  1,  0,  1],   # gak\n",
    "    [-1,  1,  0,  1,  0,  0],   # ken\n",
    "    [ 1,  0, -1,  0,  1,  0],   # update\n",
    "    [ 0,  1,  1,  0,  0, -1],   # kai\n",
    "    [ 1,  0,  0,  1, -1,  0]    # access\n",
    "])\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 2. Matriks bobot proyeksi 0Query, Key, dan Value\n",
    "#    (6 dimensi → 3 dimensi)\n",
    "# -------------------------------------------------------------\n",
    "WQ = np.array([\n",
    "    [ 1,  0,  1],\n",
    "    [ 0,  1, -1],\n",
    "    [ 1, -1,  0],\n",
    "    [ 0,  1,  0],\n",
    "    [-1,  0,  1],\n",
    "    [ 1,  0, -1]\n",
    "])\n",
    "\n",
    "WK = np.array([\n",
    "    [ 0,  1,  0],\n",
    "    [ 1, -1,  0],\n",
    "    [-1,  0,  1],\n",
    "    [ 1,  0, -1],\n",
    "    [ 0,  1,  1],\n",
    "    [ 1,  0,  0]\n",
    "])\n",
    "\n",
    "WV = np.array([\n",
    "    [ 1,  0,  0],\n",
    "    [ 0,  1,  0],\n",
    "    [ 1,  1, -1],\n",
    "    [ 0,  0,  1],\n",
    "    [ 1,  0,  1],\n",
    "    [ 0, -1,  1]\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7621cb80",
   "metadata": {},
   "source": [
    "# -------------------------------------------------------------\n",
    "# 3. Menghitung Q, K, V\n",
    "# -------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "00e8114f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3, -1,  0],\n",
       "       [-1,  0,  0],\n",
       "       [ 2, -1,  1],\n",
       "       [ 0,  2, -1],\n",
       "       [-1,  2, -2],\n",
       "       [-1,  1,  2],\n",
       "       [ 0,  0,  0],\n",
       "       [ 2,  1,  0]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q = X @ WQ\n",
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "78293809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1,  0,  0],\n",
       "       [ 0,  0,  2],\n",
       "       [ 0,  2,  0],\n",
       "       [ 3,  0, -2],\n",
       "       [ 2, -2, -1],\n",
       "       [ 1,  2,  0],\n",
       "       [-1, -1,  1],\n",
       "       [ 1,  0, -2]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = X @ WK\n",
    "K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d18f1361",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  1, -2],\n",
       "       [ 1,  1,  0],\n",
       "       [ 1, -2,  1],\n",
       "       [-1, -2,  3],\n",
       "       [-1,  1,  1],\n",
       "       [ 1, -1,  2],\n",
       "       [ 1,  3, -2],\n",
       "       [ 0,  0,  0]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V = X @ WV\n",
    "V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d0bcea4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1,  0,  0,  3,  2,  1, -1,  1],\n",
       "       [ 0,  0,  2,  0, -2,  2, -1,  0],\n",
       "       [ 0,  2,  0, -2, -1,  0,  1, -2]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "1ef8c9a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3,  0, -2,  9,  8,  1, -2,  3],\n",
       "       [ 1,  0,  0, -3, -2, -1,  1, -1],\n",
       "       [-2,  2, -2,  4,  5,  0,  0,  0],\n",
       "       [ 0, -2,  4,  2, -3,  4, -3,  2],\n",
       "       [ 1, -4,  4,  1, -4,  3, -3,  3],\n",
       "       [ 1,  4,  2, -7, -6,  1,  2, -5],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [-2,  0,  2,  6,  2,  4, -3,  2]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Qkt = Q @ K.T\n",
    "# Qkt\n",
    "# -------------------------------------------------------------\n",
    "# 4. Attention Score (QKᵀ)\n",
    "# -------------------------------------------------------------\n",
    "attention_scores1 = Q @ K.T\n",
    "attention_scores1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d522f13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # -------------------------------------------------------------\n",
    "# # 5. Softmax untuk bobot perhatian\n",
    "# # -------------------------------------------------------------\n",
    "# # def softmax(x):\n",
    "# #     e = np.exp(x - np.max(x))\n",
    "# #     return e / e.sum(axis=-1, keepdims=True)\n",
    "# def softmax(x):\n",
    "#     # stabilitas numerik: kurangi nilai maksimum di tiap baris\n",
    "#     e_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "#     return e_x / np.sum(e_x, axis=1, keepdims=True)\n",
    "\n",
    "# attention_weights1 = softmax(attention_scores1)\n",
    "\n",
    "# # -------------------------------------------------------------\n",
    "# # 6. Attention Output\n",
    "# # -------------------------------------------------------------\n",
    "# attention_output1 = attention_weights1 @ V\n",
    "\n",
    "# print(\"\\nAttention Scores:\\n\", attention_scores1)\n",
    "# print(\"\\nAttention Weights:\\n\", attention_weights1)\n",
    "# print(\"\\nContextual Embedding (Attention Output):\\n\", attention_output1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "867b9849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.73205081,  0.        , -1.15470054,  5.19615242,  4.61880215,\n",
       "         0.57735027, -1.15470054,  1.73205081],\n",
       "       [ 0.57735027,  0.        ,  0.        , -1.73205081, -1.15470054,\n",
       "        -0.57735027,  0.57735027, -0.57735027],\n",
       "       [-1.15470054,  1.15470054, -1.15470054,  2.30940108,  2.88675135,\n",
       "         0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        , -1.15470054,  2.30940108,  1.15470054, -1.73205081,\n",
       "         2.30940108, -1.73205081,  1.15470054],\n",
       "       [ 0.57735027, -2.30940108,  2.30940108,  0.57735027, -2.30940108,\n",
       "         1.73205081, -1.73205081,  1.73205081],\n",
       "       [ 0.57735027,  2.30940108,  1.15470054, -4.04145188, -3.46410162,\n",
       "         0.57735027,  1.15470054, -2.88675135],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ],\n",
       "       [-1.15470054,  0.        ,  1.15470054,  3.46410162,  1.15470054,\n",
       "         2.30940108, -1.73205081,  1.15470054]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_k = 3\n",
    "sqrt_dk = np.sqrt(d_k)\n",
    "scaled_attention_logits = attention_scores1 / sqrt_dk\n",
    "scaled_attention_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "cb982bfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.07581153e-04, 3.43419065e-03, 1.08229171e-03, 6.20132834e-01,\n",
       "        3.48132597e-01, 6.11736562e-03, 1.08229171e-03, 1.94108481e-02],\n",
       "       [2.48181232e-01, 1.39324951e-01, 1.39324951e-01, 2.46495384e-02,\n",
       "        4.39085229e-02, 7.82147864e-02, 2.48181232e-01, 7.82147864e-02],\n",
       "       [9.05434064e-03, 9.11626568e-02, 9.05434064e-03, 2.89265770e-01,\n",
       "        5.15272638e-01, 2.87300844e-02, 2.87300844e-02, 2.87300844e-02],\n",
       "       [3.55215487e-02, 1.11946835e-02, 3.57644900e-01, 1.12712469e-01,\n",
       "        6.28451524e-03, 3.57644900e-01, 6.28451524e-03, 1.12712469e-01],\n",
       "       [7.03768664e-02, 3.92400675e-03, 3.97786494e-01, 7.03768664e-02,\n",
       "        3.92400675e-03, 2.23310939e-01, 6.98988099e-03, 2.23310939e-01],\n",
       "       [8.87028441e-02, 5.01369202e-01, 1.58007456e-01, 8.75018543e-04,\n",
       "        1.55868118e-03, 8.87028441e-02, 1.58007456e-01, 2.77649777e-03],\n",
       "       [1.25000000e-01, 1.25000000e-01, 1.25000000e-01, 1.25000000e-01,\n",
       "        1.25000000e-01, 1.25000000e-01, 1.25000000e-01, 1.25000000e-01],\n",
       "       [5.94318631e-03, 1.88581644e-02, 5.98383334e-02, 6.02475836e-01,\n",
       "        5.98383334e-02, 1.89871404e-01, 3.33640919e-03, 5.98383334e-02]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def softmax(x):\n",
    "    # stabilitas numerik: kurangi nilai maksimum di tiap baris\n",
    "    e_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "    return e_x / np.sum(e_x, axis=1, keepdims=True)\n",
    "\n",
    "# def softmax1(x):\n",
    "#     e = np.exp(x - np.max(x))\n",
    "#     return e / e.sum(axis=-1, keepdims=True)\n",
    "\n",
    "attention_weights2 = softmax(scaled_attention_logits)\n",
    "attention_weights2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "95e6916d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.001 0.003 0.001 0.620 0.348 0.006 0.001 0.019]\n",
      " [0.248 0.139 0.139 0.025 0.044 0.078 0.248 0.078]\n",
      " [0.009 0.091 0.009 0.289 0.515 0.029 0.029 0.029]\n",
      " [0.036 0.011 0.358 0.113 0.006 0.358 0.006 0.113]\n",
      " [0.070 0.004 0.398 0.070 0.004 0.223 0.007 0.223]\n",
      " [0.089 0.501 0.158 0.001 0.002 0.089 0.158 0.003]\n",
      " [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      " [0.006 0.019 0.060 0.602 0.060 0.190 0.003 0.060]]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(formatter={'float': lambda x: f\"{x:0.3f}\"})\n",
    "\n",
    "print(attention_weights2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "bdece90a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.95594171, -0.89312637,  2.21846838],\n",
       "       [ 0.78466909,  0.76979464, -0.57911326],\n",
       "       [-0.6378069 ,  0.07630958,  1.37401561],\n",
       "       [ 0.64929356, -1.22650534,  1.33374449],\n",
       "       [ 0.62808731, -1.06044314,  0.90472948],\n",
       "       [ 0.9923561 ,  0.6591853 , -0.15382372],\n",
       "       [ 0.375     ,  0.125     ,  0.375     ],\n",
       "       [-0.38446667, -1.41985083,  2.28828779]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_output = attention_weights2 @ V\n",
    "attention_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "a7f6d839",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "wq2, wk2, wv2 = [np.random.randint(-1, 2, (9, 3)) for _ in range(3)]\n",
    "wq3, wk3, wv3 = [np.random.randint(-1, 2, (9, 3)) for _ in range(3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "734732ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x, axis=-1, keepdims=True))\n",
    "    return e_x / np.sum(e_x, axis=-1, keepdims=True)\n",
    "\n",
    "def attention(X, Wq, Wk, Wv):\n",
    "    d_k = Wq.shape[1]\n",
    "    Q, K, V = X @ Wq, X @ Wk, X @ Wv\n",
    "    scores = (Q @ K.T) / np.sqrt(d_k)\n",
    "    weights = softmax(scores)\n",
    "    return weights @ V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "227b2437",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 9 is different from 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[105]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m head2 = \u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwq2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwk2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwv2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m head3 = attention(X, wq3, wk3, wv3)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[104]\u001b[39m\u001b[32m, line 7\u001b[39m, in \u001b[36mattention\u001b[39m\u001b[34m(X, Wq, Wk, Wv)\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mattention\u001b[39m(X, Wq, Wk, Wv):\n\u001b[32m      6\u001b[39m     d_k = Wq.shape[\u001b[32m1\u001b[39m]\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     Q, K, V = \u001b[43mX\u001b[49m\u001b[43m \u001b[49m\u001b[43m@\u001b[49m\u001b[43m \u001b[49m\u001b[43mWq\u001b[49m, X @ Wk, X @ Wv\n\u001b[32m      8\u001b[39m     scores = (Q @ K.T) / np.sqrt(d_k)\n\u001b[32m      9\u001b[39m     weights = softmax(scores)\n",
      "\u001b[31mValueError\u001b[39m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 9 is different from 6)"
     ]
    }
   ],
   "source": [
    "head2 = attention(X, wq2, wk2, wv2)\n",
    "head3 = attention(X, wq3, wk3, wv3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "86ef371a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.318, -0.560, -1.352],\n",
       "       [-0.404, -0.818, -0.823],\n",
       "       [-0.966, -1.932, -0.969],\n",
       "       [0.009, -0.984, -0.997],\n",
       "       [0.019, 0.851, -1.920],\n",
       "       [-0.111, 0.171, -0.968],\n",
       "       [0.480, -0.484, -1.483],\n",
       "       [-0.001, 0.897, -1.815]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "90c2ec9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.716, 2.349, 1.096],\n",
       "       [-2.860, 1.814, 0.886],\n",
       "       [-3.632, 2.502, 1.549],\n",
       "       [-1.412, 2.551, 1.983],\n",
       "       [-1.058, 2.012, 0.035],\n",
       "       [-1.731, 1.885, -0.321],\n",
       "       [-1.441, 2.192, 0.572],\n",
       "       [-3.571, 0.524, -2.125]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "343c3d9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.167, -0.426, 1.981, 0.318, -0.560, -1.352, -2.716, 2.349,\n",
       "        1.096],\n",
       "       [2.249, -0.971, 1.100, -0.404, -0.818, -0.823, -2.860, 1.814,\n",
       "        0.886],\n",
       "       [2.249, -0.971, 1.100, -0.966, -1.932, -0.969, -3.632, 2.502,\n",
       "        1.549],\n",
       "       [-0.796, -1.880, 5.464, 0.009, -0.984, -0.997, -1.412, 2.551,\n",
       "        1.983],\n",
       "       [-0.085, -0.981, 2.796, 0.019, 0.851, -1.920, -1.058, 2.012,\n",
       "        0.035],\n",
       "       [2.365, -1.072, 1.335, -0.111, 0.171, -0.968, -1.731, 1.885,\n",
       "        -0.321],\n",
       "       [1.000, -1.000, 1.206, 0.480, -0.484, -1.483, -1.441, 2.192,\n",
       "        0.572],\n",
       "       [0.579, -1.232, 2.166, -0.001, 0.897, -1.815, -3.571, 0.524,\n",
       "        -2.125]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_head_concat = np.concatenate([attention_output, head2, head3], axis=1)\n",
    "multi_head_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "527d6469",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0, -1,  0, -1, -1,  0,  0],\n",
       "       [ 0,  1,  0,  1, -1,  1,  0, -1, -1],\n",
       "       [-1,  1,  0, -1, -1, -1,  1,  1,  0],\n",
       "       [ 1, -1,  0, -1, -1,  1,  0,  1,  1],\n",
       "       [ 0, -1, -1,  0, -1,  0,  0,  1,  0],\n",
       "       [ 1, -1, -1, -1, -1,  1, -1,  0,  0],\n",
       "       [ 0,  1, -1, -1, -1,  1,  0,  0, -1],\n",
       "       [ 0,  0,  1,  1,  1,  1, -1,  1,  0],\n",
       "       [-1,  0,  0,  0,  1,  1, -1, -1,  1]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_o = np.random.randint(-1, 2, (9, 9))\n",
    "W_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5b2c3c0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4.110, 0.433, 6.976, 2.525, 6.198, -3.877, -1.279, 3.419, 4.555],\n",
       "       [-3.214, -0.685, 6.315, 1.581, 7.476, -5.708, -3.026, 1.778,\n",
       "        4.312],\n",
       "       [-4.585, 0.365, 9.035, 3.748, 11.421, -5.836, -4.231, 0.126,\n",
       "        5.186],\n",
       "       [-8.436, 4.145, 5.943, -1.598, 4.334, -4.414, 2.723, 6.935, 5.283],\n",
       "       [-4.732, 1.807, 4.138, 1.279, 2.339, -4.605, 2.754, 6.623, 2.092],\n",
       "       [-2.094, -0.559, 4.414, -0.076, 3.941, -6.018, -1.626, 4.672,\n",
       "        2.371],\n",
       "       [-2.782, 0.252, 5.600, 1.431, 5.486, -2.888, -1.074, 3.822, 3.493],\n",
       "       [-1.857, -1.718, 5.012, 1.934, 1.954, -10.964, 5.003, 6.943,\n",
       "        2.677]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_output_final = multi_head_concat @ W_o\n",
    "attention_output_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b6630208",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.362, -0.530, 0.105, 0.205, -0.558, 0.014, -0.316, 0.168,\n",
       "        -0.376],\n",
       "       [0.220, -0.131, 0.504, -0.419, -0.184, -0.446, 0.490, 0.436,\n",
       "        -0.280],\n",
       "       [0.185, 0.366, 0.064, 0.034, -0.298, -0.470, 0.459, 0.462, 0.154],\n",
       "       [-0.186, -0.174, 0.261, 0.459, 0.447, 0.323, 0.164, -0.480,\n",
       "        -0.391],\n",
       "       [0.460, 0.123, -0.567, -0.460, 0.189, -0.572, -0.392, 0.056,\n",
       "        0.222],\n",
       "       [0.175, -0.318, 0.245, -0.303, -0.202, 0.285, 0.173, 0.403, 0.182],\n",
       "       [0.079, -0.469, -0.153, -0.271, -0.296, 0.546, -0.123, 0.453,\n",
       "        0.151],\n",
       "       [0.340, 0.003, 0.089, -0.009, -0.352, 0.257, -0.253, -0.549,\n",
       "        0.168],\n",
       "       [-0.373, 0.509, 0.524, 0.479, -0.150, -0.560, 0.495, -0.083,\n",
       "        0.539]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def xavier_uniform(shape, rng=np.random):\n",
    "    fan_in, fan_out = shape[0], shape[1]\n",
    "    limit = np.sqrt(6.0/(fan_in + fan_out))\n",
    "    return rng.uniform(-limit, limit, size=shape)\n",
    "\n",
    "W_o_xavier = xavier_uniform((9, 9), np.random)\n",
    "W_o_xavier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "714fe53a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.527, 2.307, 1.301, 2.540, -1.043, -2.179, 0.652, -2.414,\n",
       "        0.064],\n",
       "       [-1.209, 1.367, 1.035, 2.530, -1.500, -1.542, -0.238, -2.086,\n",
       "        -0.229],\n",
       "       [-1.717, 2.076, 2.011, 3.351, -2.046, -1.744, 0.330, -2.720,\n",
       "        0.073],\n",
       "       [0.271, 4.543, 1.114, 2.881, -1.598, -2.683, 2.560, -1.092, 2.545],\n",
       "       [0.971, 2.431, -0.914, 0.974, -0.450, -1.985, -0.195, -1.471,\n",
       "        0.764],\n",
       "       [-0.292, 0.379, -0.306, 1.443, -1.447, -0.807, -1.334, -1.573,\n",
       "        -0.598],\n",
       "       [-0.513, 1.345, 0.428, 2.203, -0.743, -0.642, -0.335, -2.470,\n",
       "        -0.018],\n",
       "       [0.703, 1.932, -1.898, 0.791, 0.982, -2.116, -1.202, -1.847,\n",
       "        -1.269]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attentioin_final_xavier = multi_head_concat @ W_o_xavier\n",
    "attentioin_final_xavier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "94be86f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 9)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attentioin_final_xavier.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "467b10c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.04405829,  0.10687363,  0.21846838],\n",
       "       [ 1.78466909,  1.76979464, -0.57911326],\n",
       "       [ 0.3621931 , -1.92369042,  2.37401561],\n",
       "       [-0.35070644, -3.22650534,  4.33374449],\n",
       "       [-0.37191269, -0.06044314,  1.90472948],\n",
       "       [ 1.9923561 , -0.3408147 ,  1.84617628],\n",
       "       [ 1.375     ,  3.125     , -1.625     ],\n",
       "       [-0.38446667, -1.41985083,  2.28828779]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def layer_norm(x, eps=1e-5):\n",
    "    # normalisasi per token (per baris)\n",
    "    mu  = x.mean(axis=1, keepdims=True)\n",
    "    var = x.var(axis=1, keepdims=True)\n",
    "    return (x - mu) / np.sqrt(var + eps), mu.squeeze(), np.sqrt(var + eps).squeeze()\n",
    "\n",
    "residual = V + attention_output\n",
    "residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "350c152b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.09531144, -0.2252231 ,  1.32053454],\n",
       "       [ 0.71378865,  0.70039805, -1.4141867 ],\n",
       "       [ 0.05203195, -1.24992963,  1.19789769],\n",
       "       [-0.19349487, -1.11647895,  1.30997382],\n",
       "       [-0.85597265, -0.54693334,  1.40290599],\n",
       "       [ 0.77449179, -1.411994  ,  0.63750221],\n",
       "       [ 0.21242937,  1.10463271, -1.31706208],\n",
       "       [-0.34935844, -1.0121044 ,  1.36146284]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normed, row_mean, row_std = layer_norm(residual)\n",
    "normed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1780946b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.12313343, 0.99178349, 0.27083943, 0.25217757, 0.49079122,\n",
       "       1.1659059 , 0.95833333, 0.16132343])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "653dd267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.07219421, 1.11081285, 1.75572272, 3.11576221, 1.00786387,\n",
       "       1.06708711, 1.96143627, 1.56226399])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7072ddea",
   "metadata": {},
   "source": [
    "## FFNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313c5fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# def xavier_uniform(shape, rng=np.random):\n",
    "#     fan_in, fan_out = shape[0], shape[1]\n",
    "#     limit = np.sqrt(6.0 / (fan_in + fan_out))\n",
    "#     return rng.uniform(-limit, limit, size=shape)\n",
    "\n",
    "# # === FFNN layer 1 ===\n",
    "# def ffnn_layer1(X, out_dim=18, bias_value=1.0, seed=42):\n",
    "#     \"\"\"\n",
    "#     X         : numpy array (N, D_in) -> input hasil LayerNorm\n",
    "#     out_dim   : jumlah neuron layer FF pertama (default 18)\n",
    "#     bias_value: nilai bias (default 1)\n",
    "#     seed      : agar hasil acak reproducible\n",
    "#     \"\"\"\n",
    "#     np.random.seed(seed)\n",
    "\n",
    "#     N, D_in = X.shape  # misal (8, 9)\n",
    "#     D_out = out_dim    # misal 18\n",
    "\n",
    "#     # Inisialisasi bobot dan bias\n",
    "#     W1 = xavier_uniform((D_in, D_out))\n",
    "#     b1 = np.full((D_out,), bias_value, dtype=float)\n",
    "\n",
    "#     # Linear transform (belum ReLU)\n",
    "#     Z = np.dot(X, W1) + b1  # (8×9) · (9×18) + (1×18) -> (8×18)\n",
    "\n",
    "#     return Z, W1, b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "df47737c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# === He Initialization (Kaiming) ===\n",
    "def he_initialization(shape, rng=np.random):\n",
    "    \"\"\"\n",
    "    shape: (fan_in, fan_out)\n",
    "    menggunakan distribusi normal std = sqrt(2/fan_in)\n",
    "    \"\"\"\n",
    "    fan_in = shape[0]\n",
    "    std = np.sqrt(2.0 / fan_in)\n",
    "    return rng.normal(0.0, std, size=shape)\n",
    "\n",
    "# === FFNN Layer 1 ===\n",
    "def ffnn_layer1(X, out_dim=18, bias_value=1.0, seed=42):\n",
    "    \"\"\"\n",
    "    X         : numpy array (N, D_in) hasil LayerNorm\n",
    "    out_dim   : jumlah neuron hidden layer FF pertama\n",
    "    bias_value: nilai bias (bias default = 1)\n",
    "    seed      : untuk reproducibility\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    N, D_in = X.shape\n",
    "    D_out = out_dim\n",
    "\n",
    "    # Bobot dari He Initialization\n",
    "    W1 = he_initialization((D_in, D_out))\n",
    "    b1 = np.full((D_out,), bias_value, dtype=float)\n",
    "\n",
    "    # Linear transform\n",
    "    Z = np.dot(X, W1) + b1\n",
    "\n",
    "    return Z, W1, b1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "f0128203",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(formatter={'float': lambda x: f\"{x:0.3f}\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "754519ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z shape: (8, 18)\n",
      "W1 shape: (3, 18)\n",
      "W1:\n",
      " [[ 0.4056 -0.1129  0.5288  1.2435 -0.1912 -0.1912  1.2894  0.6266 -0.3833\n",
      "   0.443  -0.3784 -0.3803  0.1976 -1.5622 -1.4084 -0.4591 -0.827   0.2566]\n",
      " [-0.7414 -1.1531  1.1967 -0.1843  0.0551 -1.1633 -0.4445  0.0906 -0.9398\n",
      "   0.3068 -0.4904 -0.2382 -0.4913  1.5124 -0.011  -0.8636  0.6716 -0.9968]\n",
      " [ 0.1705 -1.6001 -1.0845  0.1607  0.603   0.1399 -0.0944 -0.2459 -1.2072\n",
      "  -0.5878 -0.3761  0.8631  0.2806 -1.4395  0.2646 -0.3144 -0.5527  0.4994]]\n",
      "b1 shape: (18,)\n",
      "\n",
      "Preview output Z (belum ReLU):\n",
      " [[ 0.9478 -0.729  -1.2798 -0.108   1.9928  1.6558 -0.4366 -0.031   0.0377\n",
      "  -0.3299  1.0282  2.6093  1.2646  0.4701  2.894   1.282   1.0249  1.6026]\n",
      " [ 0.5281  2.3752  3.7505  1.53    0.0492 -0.1498  1.7414  1.8581  1.7761\n",
      "   2.3626  0.9186 -0.6594  0.3995  2.9833 -0.3863  0.5122  1.6632 -0.2225]\n",
      " [ 2.1514  0.5175 -1.7664  1.4875  1.6435  2.6106  1.5091  0.6249  0.7076\n",
      "  -0.0642  1.1423  2.3117  1.96   -2.6947  1.2575  1.6781 -0.544   2.8567]\n",
      " [ 1.9725  0.2126 -1.8582  1.1763  1.7652  2.5184  1.1235  0.4559  0.5413\n",
      "  -0.1978  1.1276  2.4699  1.8777 -2.2721  1.6308  1.6405 -0.3139  2.7172]\n",
      " [ 1.298  -0.5176 -1.6282  0.2631  1.9793  1.9961  0.0082  0.0698  0.1481\n",
      "  -0.3712  1.0641  2.6664  1.4935 -0.5112  2.5815  1.4238  0.5642  2.0266]\n",
      " [ 2.4696  1.52   -0.9723  2.3254  1.1589  2.5839  2.5654  1.2003  1.2601\n",
      "   0.5348  1.1596  1.5926  2.0256 -3.263   0.0943  1.6635 -0.941   2.9247]\n",
      " [ 0.043   1.8087  3.8604  0.8486  0.2269 -0.509   0.9069  1.5564  1.4699\n",
      "   2.2061  0.8733 -0.4794  0.1303  4.2329  0.341   0.363   2.2935 -0.7033]\n",
      " [ 1.841   0.0271 -1.8727  0.9715  1.8322  2.4346  0.8712  0.3548  0.4406\n",
      "  -0.2656  1.1161  2.5493  1.8104 -1.9459  1.8631  1.606  -0.1438  2.5995]]\n"
     ]
    }
   ],
   "source": [
    "layer_norm_x = np.array([\n",
    "    [-1.095, -0.225, 1.320],\n",
    "    [ 0.713,  0.701, -1.415],\n",
    "    [ 0.052, -1.249,  1.198],\n",
    "    [-0.193, -1.116,  1.310],\n",
    "    [-0.855, -0.547,  1.403],\n",
    "    [ 0.774, -1.412,  0.638],\n",
    "    [ 0.212,  1.104, -1.316],\n",
    "    [-0.349, -1.012,  1.362]\n",
    "], dtype=float)\n",
    "\n",
    "# Jalankan layer FFNN pertama\n",
    "Z, W1, b1 = ffnn_layer1(layer_norm_x, out_dim=18, bias_value=1.0, seed=42)\n",
    "\n",
    "print(\"Z shape:\", Z.shape)\n",
    "print(\"W1 shape:\", W1.shape)\n",
    "print(\"W1:\\n\", np.round(W1, 4))\n",
    "print(\"b1 shape:\", b1.shape)\n",
    "print(\"\\nPreview output Z (belum ReLU):\\n\", np.round(Z, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "3c05f727",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.94782862, 0.        , 0.        , 0.        , 1.9928435 ,\n",
       "        1.65577285, 0.        , 0.        , 0.0376763 , 0.        ,\n",
       "        1.02820416, 2.60932008, 1.26455424, 0.47014783, 2.89395587,\n",
       "        1.28200256, 1.02485451, 1.60257586],\n",
       "       [0.52813873, 2.37524633, 3.75045444, 1.52998177, 0.04915356,\n",
       "        0.        , 1.74138605, 1.85813744, 1.77610195, 2.36256066,\n",
       "        0.9186274 , 0.        , 0.39946912, 2.98325388, 0.        ,\n",
       "        0.51216375, 1.66324019, 0.        ],\n",
       "       [2.15139881, 0.51752627, 0.        , 1.48747452, 1.64353342,\n",
       "        2.61064938, 1.50909088, 0.62493582, 0.70761989, 0.        ,\n",
       "        1.14227841, 2.3117344 , 1.9600108 , 0.        , 1.25753519,\n",
       "        1.67811137, 0.        , 2.85668283],\n",
       "       [1.97252936, 0.21260995, 0.        , 1.17628962, 1.76523802,\n",
       "        2.51843857, 1.12349004, 0.45592721, 0.54133597, 0.        ,\n",
       "        1.12763116, 2.46989485, 1.87768959, 0.        , 1.63076161,\n",
       "        1.64051634, 0.        , 2.71718026],\n",
       "       [1.29804917, 0.        , 0.        , 0.26311626, 1.97925033,\n",
       "        1.99608831, 0.00819822, 0.06978191, 0.14809011, 0.        ,\n",
       "        1.06409114, 2.66638616, 1.49345153, 0.        , 2.58145389,\n",
       "        1.42380523, 0.56424963, 2.02658265],\n",
       "       [2.46956461, 1.52001583, 0.        , 2.32535253, 1.15885524,\n",
       "        2.5838853 , 2.56538359, 1.20026018, 1.26008088, 0.53475638,\n",
       "        1.15964876, 1.59264647, 2.02561524, 0.        , 0.09429076,\n",
       "        1.66348087, 0.        , 2.92473404],\n",
       "       [0.04304995, 1.80868317, 3.86041537, 0.84858553, 0.22685008,\n",
       "        0.        , 0.90690937, 1.55636662, 1.46990151, 2.20605389,\n",
       "        0.87332134, 0.        , 0.1302762 , 4.232886  , 0.34102356,\n",
       "        0.36301057, 2.29349285, 0.        ],\n",
       "       [1.8410236 , 0.02709115, 0.        , 0.97148239, 1.83215083,\n",
       "        2.43455392, 0.87120345, 0.35481125, 0.44062236, 0.        ,\n",
       "        1.11609693, 2.54933021, 1.81036499, 0.        , 1.86308415,\n",
       "        1.60597089, 0.        , 2.59945521]])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z1_relu = np.maximum(0, Z)\n",
    "Z1_relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "68292488",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 18)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z1_relu.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "c9b839c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W2 shape: (18, 3)\n",
      "b2 shape: (3,)\n",
      "Z2 shape: (8, 3)\n",
      "W2:\n",
      " [[ 0.3437  0.3104 -0.2797]\n",
      " [-0.1031  0.1104  0.3252]\n",
      " [-0.1597 -0.0619 -0.3688]\n",
      " [-0.3987  0.2708  0.4521]\n",
      " [-0.024   0.3345  0.1205]\n",
      " [-0.215   0.1205  0.5127]\n",
      " [-0.0119  0.5215 -0.8732]\n",
      " [ 0.274   0.029  -0.0997]\n",
      " [ 0.0306 -0.6625 -0.0732]\n",
      " [ 0.119   0.4926 -0.1728]\n",
      " [-0.2695 -0.1673  0.3051]\n",
      " [ 0.1096 -0.1766  0.1711]\n",
      " [ 0.0324  0.3229 -0.234 ]\n",
      " [-0.1092 -0.1307 -0.4878]\n",
      " [ 0.0987  0.087   0.0017]\n",
      " [-0.0782 -0.4718 -0.1402]\n",
      " [-0.1142 -0.2674 -0.0538]\n",
      " [ 0.1347  0.6287  0.0582]]\n",
      "\n",
      "Preview Z2 (tanpa residual & layer norm):\n",
      " [[ 1.2056  2.23    1.9194]\n",
      " [-0.2403  1.4732 -2.7347]\n",
      " [ 1.0535  4.4759  1.562 ]\n",
      " [ 1.1572  4.1466  1.745 ]\n",
      " [ 1.2937  2.7945  2.3166]\n",
      " [ 0.7825  5.3057  0.864 ]\n",
      " [-0.3591  0.4988 -2.875 ]\n",
      " [ 1.2209  3.903   1.8559]]\n"
     ]
    }
   ],
   "source": [
    "hidden_dim = Z1_relu.shape[1]                \n",
    "D_out      = layer_norm_x.shape[1]       \n",
    "\n",
    "# Inisialisasi W2, b2 dengan He Initialization & bias=1\n",
    "W2 = he_initialization((hidden_dim, D_out))\n",
    "b2 = np.full((D_out,), 1.0, dtype=float)\n",
    "\n",
    "# Linear layer-2 (tanpa aktivasi)\n",
    "Z2 = Z1_relu @ W2 + b2    # shape: (N, D_out)\n",
    "\n",
    "print(\"W2 shape:\", W2.shape)   # (hidden_dim, D_out)\n",
    "print(\"b2 shape:\", b2.shape)   # (D_out,)\n",
    "print(\"Z2 shape:\", Z2.shape)   # (N, D_out)\n",
    "print(\"W2:\\n\", np.round(W2, 4))\n",
    "print(\"\\nPreview Z2 (tanpa residual & layer norm):\\n\", np.round(Z2, 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "1a751bf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.11057643,  2.00497583,  3.23942287],\n",
       "       [ 0.47270993,  2.17423617, -4.14966024],\n",
       "       [ 1.10546884,  3.22689362,  2.76001756],\n",
       "       [ 0.96423579,  3.0306197 ,  3.05500759],\n",
       "       [ 0.43869373,  2.24749984,  3.71956225],\n",
       "       [ 1.55647262,  3.89367855,  1.50201042],\n",
       "       [-0.14710173,  1.60279417, -4.1909685 ],\n",
       "       [ 0.87190155,  2.89099214,  3.21791536]])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z2_out = layer_norm_x + Z2\n",
    "Z2_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "5883e24f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.3012377 ,  0.17095618,  1.13028152],\n",
       "       [ 0.36438525,  1.00119887, -1.36558412],\n",
       "       [-1.3828494 ,  0.94789603,  0.43495338],\n",
       "       [-1.4141332 ,  0.69462261,  0.71951058],\n",
       "       [-1.26442527,  0.08365706,  1.18076821],\n",
       "       [-0.68253711,  1.41392659, -0.73138947],\n",
       "       [ 0.31515236,  1.03636967, -1.35152203],\n",
       "       [-1.4024562 ,  0.54367328,  0.85878292]])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def layer_norm(x, eps=1e-5):\n",
    "    # normalisasi per token (per baris)\n",
    "    mu  = x.mean(axis=1, keepdims=True)\n",
    "    var = x.var(axis=1, keepdims=True)\n",
    "    return (x - mu) / np.sqrt(var + eps), mu.squeeze(), np.sqrt(var + eps).squeeze()\n",
    "\n",
    "Z2_norm, Z_row_mean, Z_row_std = layer_norm(Z2_out)\n",
    "Z2_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "1b6c0fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z1 mean: [ 1.78499171 -0.50090471  2.36412667  2.34995436  2.13525194  2.3173872\n",
      " -0.91175869  2.32693635]\n",
      "Z1 std : [1.28678664 2.67193757 0.91019154 0.97990668 1.34176234 1.11483253\n",
      " 2.42630881 1.03749037]\n"
     ]
    }
   ],
   "source": [
    "print(\"Z1 mean:\", Z_row_mean)\n",
    "print(\"Z1 std :\", Z_row_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "c1a16a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W_linear shape: (3, 3)\n",
      "Y_linear: (8, 3)\n",
      "Preview Y_linear:\n",
      " [[0.545 1.366 3.35 ]\n",
      " [1.269 0.691 2.481]\n",
      " [0.62  1.238 5.061]\n",
      " [0.575 1.297 4.592]\n",
      " [0.547 1.372 3.116]\n",
      " [0.941 0.931 4.934]\n",
      " [1.256 0.699 2.629]\n",
      " [0.558 1.323 4.266]]\n"
     ]
    }
   ],
   "source": [
    "N, D = Z2_norm.shape\n",
    "M = D\n",
    "\n",
    "W_linear = he_initialization((D, M))\n",
    "b_linear = np.ones((M,), dtype=float)\n",
    "\n",
    "y_linear = Z2_norm @ W_linear + b_linear\n",
    "\n",
    "print(\"W_linear shape:\", W_linear.shape)\n",
    "print(\"Y_linear:\", y_linear.shape)\n",
    "print(\"Preview Y_linear:\\n\", np.round(y_linear, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "feeac757",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.21028901, -0.06078484, -1.56667014],\n",
       "       [-0.02164849,  0.04917776,  2.01122876],\n",
       "       [-0.15706207,  0.24621237, -0.02834204]])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_linear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0d5172",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "577896df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLS shape: (3,)\n",
      "W_cls shape: (3, 9)\n",
      "cls_linear:\n",
      " [ 0.09  1.2   1.74 -1.9  -2.63 -1.67 -2.83  3.68 -0.63]\n",
      "cls_tanh:\n",
      " [ 0.09  0.83  0.94 -0.96 -0.99 -0.93 -0.99  1.   -0.56]\n"
     ]
    }
   ],
   "source": [
    "CLS = y_linear[0]       \n",
    "M   = CLS.shape[0]\n",
    "\n",
    "np.random.seed(77)\n",
    "\n",
    "# Linear untuk [CLS] (He Initialization)\n",
    "H_cls = 9\n",
    "W_cls = he_initialization((M, H_cls))\n",
    "b_cls = np.ones((H_cls,), dtype=float)\n",
    "\n",
    "cls_linear = CLS @ W_cls + b_cls      \n",
    "cls_tanh   = np.tanh(cls_linear)      \n",
    "\n",
    "print(\"CLS shape:\", CLS.shape)\n",
    "print(\"W_cls shape:\", W_cls.shape)\n",
    "print(\"cls_linear:\\n\", np.round(cls_linear, 2))\n",
    "print(\"cls_tanh:\\n\", np.round(cls_tanh, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "54707b13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.54513871, 1.36579206, 3.35040773])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "360c3625",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.18325845,  0.54013819, -0.47337013,  0.33297655,  0.38087881,\n",
       "        -1.61234323,  0.22498401, -1.28663954,  1.28059071],\n",
       "       [-0.59179266,  0.24975791,  0.95035479, -0.8565828 , -0.7973726 ,\n",
       "        -0.52178279,  1.38594516, -1.05010875, -0.15444979],\n",
       "       [-0.06034944, -0.13104392, -0.0888295 , -0.56908506, -0.82124109,\n",
       "        -0.32051169, -1.74550076,  1.43779405, -0.63212612]])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "48f30296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W_clf shape: (9, 2)\n",
      "logits: [0.809 1.11 ]\n",
      "softmax probs (Class A, Class B): [0.4253 0.5747]\n"
     ]
    }
   ],
   "source": [
    "feat = cls_tanh                \n",
    "F    = feat.shape[0]\n",
    "num_labels = 2\n",
    "\n",
    "np.random.seed(1313)\n",
    "\n",
    "# Bobot classifier (He Initialization) dan bias=1 \n",
    "W_clf = he_initialization((F, num_labels))\n",
    "b_clf = np.ones((num_labels,), dtype=float)\n",
    "\n",
    "logits = feat @ W_clf + b_clf      # (2,)\n",
    "# Softmax\n",
    "logits_shift = logits - logits.max()\n",
    "probs = np.exp(logits_shift) / np.exp(logits_shift).sum()\n",
    "\n",
    "print(\"W_clf shape:\", W_clf.shape)\n",
    "print(\"logits:\", np.round(logits, 3))\n",
    "print(\"softmax probs (Class A, Class B):\", np.round(probs, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "775069ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.0059573 , -0.68222747],\n",
       "       [ 0.27895013, -0.16084336],\n",
       "       [ 0.4778046 ,  0.22394529],\n",
       "       [ 0.06251485, -0.3049946 ],\n",
       "       [ 0.52724495, -0.22665598],\n",
       "       [ 0.21025446,  0.68126781],\n",
       "       [ 0.4707731 , -0.29790648],\n",
       "       [ 0.38948355,  0.07968127],\n",
       "       [ 0.02938697,  0.29220427]])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_clf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
