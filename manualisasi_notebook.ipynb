{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ad89575",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.array([\n",
    "    [0,  1,  0,  0,  0, -1, -1, -1,  0],\n",
    "    [0, -1, -1,  0,  0,  0,  1,  0,  0],\n",
    "    [-1, -1, -1,  1,  0,  0,  0,  1, -1],\n",
    "    [-1,  1, -1,  1, -1, -1,  0, -1,  0],\n",
    "    [-1,  1,  1,  1, -1, -1, -1,  0, -1],\n",
    "    [0, -1,  1,  1, -1,  1,  1,  0,  0],\n",
    "    [1,  0, -1,  1, -1,  0,  0,  0,  1],\n",
    "    [1, -1, -1,  1, -1,  0, -1, -1, -1]\n",
    "])\n",
    "\n",
    "wq = np.array([\n",
    "    [-1,  0,  1],\n",
    "    [ 1, -1,  0],\n",
    "    [ 0,  1, -1],\n",
    "    [-1,  0,  0],\n",
    "    [ 1,  1,  0],\n",
    "    [ 0, -1,  1],\n",
    "    [-1,  1, -1],\n",
    "    [ 0,  0,  1],\n",
    "    [ 1, -1,  1]\n",
    "])\n",
    "\n",
    "wk = np.array([\n",
    "    [ 0,  1, -1],\n",
    "    [ 0, -1,  0],\n",
    "    [-1, -1, -1],\n",
    "    [ 0,  1, -1],\n",
    "    [-1, -1, -1],\n",
    "    [-1,  0,  0],\n",
    "    [ 1,  0,  0],\n",
    "    [ 1,  1, -1],\n",
    "    [ 1,  1,  1]\n",
    "])\n",
    "\n",
    "wv = np.array([\n",
    "    [ 1,  0, -1],\n",
    "    [ 0,  1,  1],\n",
    "    [-1, -1,  0],\n",
    "    [ 1, -1,  1],\n",
    "    [ 0,  0, -1],\n",
    "    [-1,  1,  0],\n",
    "    [ 1,  1, -1],\n",
    "    [-1,  0,  1],\n",
    "    [ 0, -1, -1]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00e8114f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2, -1, -1],\n",
       "       [-2,  1,  0],\n",
       "       [-2,  1,  0],\n",
       "       [ 0, -2, -2],\n",
       "       [ 0,  0, -3],\n",
       "       [-4,  1, -1],\n",
       "       [-2, -3,  3],\n",
       "       [-4, -1,  1]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q = X @ wq\n",
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78293809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1, -2,  1],\n",
       "       [ 2,  2,  1],\n",
       "       [ 1,  2, -1],\n",
       "       [ 2,  0,  3],\n",
       "       [-1, -2, -1],\n",
       "       [ 0,  2, -1],\n",
       "       [ 3,  5,  1],\n",
       "       [-1,  3,  0]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = X @ wk\n",
    "K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d18f1361",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1, -1,  1],\n",
       "       [ 2,  1, -2],\n",
       "       [ 0,  0,  3],\n",
       "       [ 3,  0,  3],\n",
       "       [-1, -2,  6],\n",
       "       [ 0, -1,  0],\n",
       "       [ 3, -1,  0],\n",
       "       [ 3, -1,  1]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V = X @ wv\n",
    "V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ef8c9a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -1,   1,   1,   1,   1,  -1,   0,  -5],\n",
       "       [  0,  -2,   0,  -4,   0,   2,  -1,   5],\n",
       "       [  0,  -2,   0,  -4,   0,   2,  -1,   5],\n",
       "       [  2,  -6,  -2,  -6,   6,  -2, -12,  -6],\n",
       "       [ -3,  -3,   3,  -9,   3,   3,  -3,   0],\n",
       "       [  1,  -7,  -1, -11,   3,   3,  -8,   7],\n",
       "       [ 11,  -7, -11,   5,   5,  -9, -18,  -7],\n",
       "       [  7,  -9,  -7,  -5,   5,  -3, -16,   1]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Qkt = Q @ K.T\n",
    "Qkt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "867b9849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -0.57735027,   0.57735027,   0.57735027,   0.57735027,\n",
       "          0.57735027,  -0.57735027,   0.        ,  -2.88675135],\n",
       "       [  0.        ,  -1.15470054,   0.        ,  -2.30940108,\n",
       "          0.        ,   1.15470054,  -0.57735027,   2.88675135],\n",
       "       [  0.        ,  -1.15470054,   0.        ,  -2.30940108,\n",
       "          0.        ,   1.15470054,  -0.57735027,   2.88675135],\n",
       "       [  1.15470054,  -3.46410162,  -1.15470054,  -3.46410162,\n",
       "          3.46410162,  -1.15470054,  -6.92820323,  -3.46410162],\n",
       "       [ -1.73205081,  -1.73205081,   1.73205081,  -5.19615242,\n",
       "          1.73205081,   1.73205081,  -1.73205081,   0.        ],\n",
       "       [  0.57735027,  -4.04145188,  -0.57735027,  -6.35085296,\n",
       "          1.73205081,   1.73205081,  -4.61880215,   4.04145188],\n",
       "       [  6.35085296,  -4.04145188,  -6.35085296,   2.88675135,\n",
       "          2.88675135,  -5.19615242, -10.39230485,  -4.04145188],\n",
       "       [  4.04145188,  -5.19615242,  -4.04145188,  -2.88675135,\n",
       "          2.88675135,  -1.73205081,  -9.23760431,   0.57735027]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_k = 3\n",
    "sqrt_dk = np.sqrt(d_k)\n",
    "scaled_attention_logits = Qkt / sqrt_dk\n",
    "scaled_attention_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb982bfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.03393783e-02, 1.91461256e-01, 1.91461256e-01, 1.91461256e-01,\n",
       "        1.91461256e-01, 6.03393783e-02, 1.07483269e-01, 5.99295045e-03],\n",
       "       [3.98662408e-02, 1.25639215e-02, 3.98662408e-02, 3.95954371e-03,\n",
       "        3.98662408e-02, 1.26498495e-01, 2.23802663e-02, 7.14999051e-01],\n",
       "       [3.98662408e-02, 1.25639215e-02, 3.98662408e-02, 3.95954371e-03,\n",
       "        3.98662408e-02, 1.26498495e-01, 2.23802663e-02, 7.14999051e-01],\n",
       "       [8.85195720e-02, 8.73210636e-04, 8.79182756e-03, 8.73210636e-04,\n",
       "        8.91249809e-01, 8.79182756e-03, 2.73324650e-05, 8.73210636e-04],\n",
       "       [9.56692709e-03, 9.56692709e-03, 3.05641752e-01, 2.99455468e-04,\n",
       "        3.05641752e-01, 3.05641752e-01, 9.56692709e-03, 5.40745075e-02],\n",
       "       [2.52363219e-02, 2.48946354e-04, 7.95327477e-03, 2.47255310e-05,\n",
       "        8.00766933e-02, 8.00766933e-02, 1.39754479e-04, 8.06243590e-01],\n",
       "       [9.41020305e-01, 2.88588051e-05, 2.86627728e-06, 2.94549831e-02,\n",
       "        2.94549831e-02, 9.09490723e-06, 5.03660566e-08, 2.88588051e-05],\n",
       "       [7.40220166e-01, 7.20311480e-05, 2.28560095e-04, 7.25237881e-04,\n",
       "        2.33281791e-01, 2.30123278e-03, 1.26572712e-06, 2.31697153e-02]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def softmax(x):\n",
    "    # stabilitas numerik: kurangi nilai maksimum di tiap baris\n",
    "    e_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "    return e_x / np.sum(e_x, axis=1, keepdims=True)\n",
    "\n",
    "attention_weights = softmax(scaled_attention_logits)\n",
    "attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95e6916d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.060 0.191 0.191 0.191 0.191 0.060 0.107 0.006]\n",
      " [0.040 0.013 0.040 0.004 0.040 0.126 0.022 0.715]\n",
      " [0.040 0.013 0.040 0.004 0.040 0.126 0.022 0.715]\n",
      " [0.089 0.001 0.009 0.001 0.891 0.009 0.000 0.001]\n",
      " [0.010 0.010 0.306 0.000 0.306 0.306 0.010 0.054]\n",
      " [0.025 0.000 0.008 0.000 0.080 0.080 0.000 0.806]\n",
      " [0.941 0.000 0.000 0.029 0.029 0.000 0.000 0.000]\n",
      " [0.740 0.000 0.000 0.001 0.233 0.002 0.000 0.023]]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(formatter={'float': lambda x: f\"{x:0.3f}\"})\n",
    "\n",
    "print(attention_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bdece90a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.167, -0.426, 1.981],\n",
       "       [2.249, -0.971, 1.100],\n",
       "       [2.249, -0.971, 1.100],\n",
       "       [-0.796, -1.880, 5.464],\n",
       "       [-0.085, -0.981, 2.796],\n",
       "       [2.365, -1.072, 1.335],\n",
       "       [1.000, -1.000, 1.206],\n",
       "       [0.579, -1.232, 2.166]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_output = attention_weights @ V\n",
    "attention_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7f6d839",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "wq2, wk2, wv2 = [np.random.randint(-1, 2, (9, 3)) for _ in range(3)]\n",
    "wq3, wk3, wv3 = [np.random.randint(-1, 2, (9, 3)) for _ in range(3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "734732ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x, axis=-1, keepdims=True))\n",
    "    return e_x / np.sum(e_x, axis=-1, keepdims=True)\n",
    "\n",
    "def attention(X, Wq, Wk, Wv):\n",
    "    d_k = Wq.shape[1]\n",
    "    Q, K, V = X @ Wq, X @ Wk, X @ Wv\n",
    "    scores = (Q @ K.T) / np.sqrt(d_k)\n",
    "    weights = softmax(scores)\n",
    "    return weights @ V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "227b2437",
   "metadata": {},
   "outputs": [],
   "source": [
    "head2 = attention(X, wq2, wk2, wv2)\n",
    "head3 = attention(X, wq3, wk3, wv3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "86ef371a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.318, -0.560, -1.352],\n",
       "       [-0.404, -0.818, -0.823],\n",
       "       [-0.966, -1.932, -0.969],\n",
       "       [0.009, -0.984, -0.997],\n",
       "       [0.019, 0.851, -1.920],\n",
       "       [-0.111, 0.171, -0.968],\n",
       "       [0.480, -0.484, -1.483],\n",
       "       [-0.001, 0.897, -1.815]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "90c2ec9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.716, 2.349, 1.096],\n",
       "       [-2.860, 1.814, 0.886],\n",
       "       [-3.632, 2.502, 1.549],\n",
       "       [-1.412, 2.551, 1.983],\n",
       "       [-1.058, 2.012, 0.035],\n",
       "       [-1.731, 1.885, -0.321],\n",
       "       [-1.441, 2.192, 0.572],\n",
       "       [-3.571, 0.524, -2.125]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "343c3d9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.167, -0.426, 1.981, 0.318, -0.560, -1.352, -2.716, 2.349,\n",
       "        1.096],\n",
       "       [2.249, -0.971, 1.100, -0.404, -0.818, -0.823, -2.860, 1.814,\n",
       "        0.886],\n",
       "       [2.249, -0.971, 1.100, -0.966, -1.932, -0.969, -3.632, 2.502,\n",
       "        1.549],\n",
       "       [-0.796, -1.880, 5.464, 0.009, -0.984, -0.997, -1.412, 2.551,\n",
       "        1.983],\n",
       "       [-0.085, -0.981, 2.796, 0.019, 0.851, -1.920, -1.058, 2.012,\n",
       "        0.035],\n",
       "       [2.365, -1.072, 1.335, -0.111, 0.171, -0.968, -1.731, 1.885,\n",
       "        -0.321],\n",
       "       [1.000, -1.000, 1.206, 0.480, -0.484, -1.483, -1.441, 2.192,\n",
       "        0.572],\n",
       "       [0.579, -1.232, 2.166, -0.001, 0.897, -1.815, -3.571, 0.524,\n",
       "        -2.125]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_head_concat = np.concatenate([attention_output, head2, head3], axis=1)\n",
    "multi_head_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "527d6469",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0, -1,  0, -1, -1,  0,  0],\n",
       "       [ 0,  1,  0,  1, -1,  1,  0, -1, -1],\n",
       "       [-1,  1,  0, -1, -1, -1,  1,  1,  0],\n",
       "       [ 1, -1,  0, -1, -1,  1,  0,  1,  1],\n",
       "       [ 0, -1, -1,  0, -1,  0,  0,  1,  0],\n",
       "       [ 1, -1, -1, -1, -1,  1, -1,  0,  0],\n",
       "       [ 0,  1, -1, -1, -1,  1,  0,  0, -1],\n",
       "       [ 0,  0,  1,  1,  1,  1, -1,  1,  0],\n",
       "       [-1,  0,  0,  0,  1,  1, -1, -1,  1]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_o = np.random.randint(-1, 2, (9, 9))\n",
    "W_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5b2c3c0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4.110, 0.433, 6.976, 2.525, 6.198, -3.877, -1.279, 3.419, 4.555],\n",
       "       [-3.214, -0.685, 6.315, 1.581, 7.476, -5.708, -3.026, 1.778,\n",
       "        4.312],\n",
       "       [-4.585, 0.365, 9.035, 3.748, 11.421, -5.836, -4.231, 0.126,\n",
       "        5.186],\n",
       "       [-8.436, 4.145, 5.943, -1.598, 4.334, -4.414, 2.723, 6.935, 5.283],\n",
       "       [-4.732, 1.807, 4.138, 1.279, 2.339, -4.605, 2.754, 6.623, 2.092],\n",
       "       [-2.094, -0.559, 4.414, -0.076, 3.941, -6.018, -1.626, 4.672,\n",
       "        2.371],\n",
       "       [-2.782, 0.252, 5.600, 1.431, 5.486, -2.888, -1.074, 3.822, 3.493],\n",
       "       [-1.857, -1.718, 5.012, 1.934, 1.954, -10.964, 5.003, 6.943,\n",
       "        2.677]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_output_final = multi_head_concat @ W_o\n",
    "attention_output_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b6630208",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.362, -0.530, 0.105, 0.205, -0.558, 0.014, -0.316, 0.168,\n",
       "        -0.376],\n",
       "       [0.220, -0.131, 0.504, -0.419, -0.184, -0.446, 0.490, 0.436,\n",
       "        -0.280],\n",
       "       [0.185, 0.366, 0.064, 0.034, -0.298, -0.470, 0.459, 0.462, 0.154],\n",
       "       [-0.186, -0.174, 0.261, 0.459, 0.447, 0.323, 0.164, -0.480,\n",
       "        -0.391],\n",
       "       [0.460, 0.123, -0.567, -0.460, 0.189, -0.572, -0.392, 0.056,\n",
       "        0.222],\n",
       "       [0.175, -0.318, 0.245, -0.303, -0.202, 0.285, 0.173, 0.403, 0.182],\n",
       "       [0.079, -0.469, -0.153, -0.271, -0.296, 0.546, -0.123, 0.453,\n",
       "        0.151],\n",
       "       [0.340, 0.003, 0.089, -0.009, -0.352, 0.257, -0.253, -0.549,\n",
       "        0.168],\n",
       "       [-0.373, 0.509, 0.524, 0.479, -0.150, -0.560, 0.495, -0.083,\n",
       "        0.539]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def xavier_uniform(shape, rng=np.random):\n",
    "    fan_in, fan_out = shape[0], shape[1]\n",
    "    limit = np.sqrt(6.0/(fan_in + fan_out))\n",
    "    return rng.uniform(-limit, limit, size=shape)\n",
    "\n",
    "W_o_xavier = xavier_uniform((9, 9), np.random)\n",
    "W_o_xavier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "714fe53a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.527, 2.307, 1.301, 2.540, -1.043, -2.179, 0.652, -2.414,\n",
       "        0.064],\n",
       "       [-1.209, 1.367, 1.035, 2.530, -1.500, -1.542, -0.238, -2.086,\n",
       "        -0.229],\n",
       "       [-1.717, 2.076, 2.011, 3.351, -2.046, -1.744, 0.330, -2.720,\n",
       "        0.073],\n",
       "       [0.271, 4.543, 1.114, 2.881, -1.598, -2.683, 2.560, -1.092, 2.545],\n",
       "       [0.971, 2.431, -0.914, 0.974, -0.450, -1.985, -0.195, -1.471,\n",
       "        0.764],\n",
       "       [-0.292, 0.379, -0.306, 1.443, -1.447, -0.807, -1.334, -1.573,\n",
       "        -0.598],\n",
       "       [-0.513, 1.345, 0.428, 2.203, -0.743, -0.642, -0.335, -2.470,\n",
       "        -0.018],\n",
       "       [0.703, 1.932, -1.898, 0.791, 0.982, -2.116, -1.202, -1.847,\n",
       "        -1.269]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attentioin_final_xavier = multi_head_concat @ W_o_xavier\n",
    "attentioin_final_xavier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "94be86f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 9)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attentioin_final_xavier.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "467b10c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.527, 3.307, 1.301, 2.540, -1.043, -3.179, -0.348, -3.414,\n",
       "        0.064],\n",
       "       [-1.209, 0.367, 0.035, 2.530, -1.500, -1.542, 0.762, -2.086,\n",
       "        -0.229],\n",
       "       [-2.717, 1.076, 1.011, 4.351, -2.046, -1.744, 0.330, -1.720,\n",
       "        -0.927],\n",
       "       [-0.729, 5.543, 0.114, 3.881, -2.598, -3.683, 2.560, -2.092,\n",
       "        2.545],\n",
       "       [-0.029, 3.431, 0.086, 1.974, -1.450, -2.985, -1.195, -1.471,\n",
       "        -0.236],\n",
       "       [-0.292, -0.621, 0.694, 2.443, -2.447, 0.193, -0.334, -1.573,\n",
       "        -0.598],\n",
       "       [0.487, 1.345, -0.572, 3.203, -1.743, -0.642, -0.335, -2.470,\n",
       "        0.982],\n",
       "       [1.703, 0.932, -2.898, 1.791, -0.018, -2.116, -2.202, -2.847,\n",
       "        -2.269]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def layer_norm(x, eps=1e-5):\n",
    "    # normalisasi per token (per baris)\n",
    "    mu  = x.mean(axis=1, keepdims=True)\n",
    "    var = x.var(axis=1, keepdims=True)\n",
    "    return (x - mu) / np.sqrt(var + eps), mu.squeeze(), np.sqrt(var + eps).squeeze()\n",
    "\n",
    "residual = X + attentioin_final_xavier\n",
    "residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "350c152b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.177, 1.595, 0.668, 1.240, -0.415, -1.402, -0.094, -1.511,\n",
       "        0.096],\n",
       "       [-0.653, 0.504, 0.260, 2.092, -0.867, -0.898, 0.794, -1.297,\n",
       "        0.066],\n",
       "       [-1.178, 0.644, 0.613, 2.217, -0.855, -0.710, 0.286, -0.699,\n",
       "        -0.318],\n",
       "       [-0.449, 1.646, -0.167, 1.091, -1.074, -1.436, 0.650, -0.904,\n",
       "        0.645],\n",
       "       [0.098, 1.995, 0.161, 1.197, -0.681, -1.522, -0.541, -0.692,\n",
       "        -0.015],\n",
       "       [-0.008, -0.261, 0.751, 2.098, -1.668, 0.365, -0.040, -0.995,\n",
       "        -0.243],\n",
       "       [0.285, 0.819, -0.374, 1.975, -1.102, -0.417, -0.226, -1.554,\n",
       "        0.593],\n",
       "       [1.392, 0.977, -1.087, 1.440, 0.465, -0.666, -0.712, -1.060,\n",
       "        -0.749]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normed, row_mean, row_std = layer_norm(residual)\n",
    "normed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1780946b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.144, -0.319, -0.265, 0.616, -0.208, -0.282, 0.029, -0.880])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "653dd267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.164, 1.362, 2.082, 2.993, 1.824, 1.299, 1.607, 1.855])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7072ddea",
   "metadata": {},
   "source": [
    "## FFNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "313c5fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def xavier_uniform(shape, rng=np.random):\n",
    "    fan_in, fan_out = shape[0], shape[1]\n",
    "    limit = np.sqrt(6.0 / (fan_in + fan_out))\n",
    "    return rng.uniform(-limit, limit, size=shape)\n",
    "\n",
    "# === FFNN layer 1 ===\n",
    "def ffnn_layer1(X, out_dim=18, bias_value=1.0, seed=42):\n",
    "    \"\"\"\n",
    "    X         : numpy array (N, D_in) -> input hasil LayerNorm\n",
    "    out_dim   : jumlah neuron layer FF pertama (default 18)\n",
    "    bias_value: nilai bias (default 1)\n",
    "    seed      : agar hasil acak reproducible\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    N, D_in = X.shape  # misal (8, 9)\n",
    "    D_out = out_dim    # misal 18\n",
    "\n",
    "    # Inisialisasi bobot dan bias\n",
    "    W1 = xavier_uniform((D_in, D_out))\n",
    "    b1 = np.full((D_out,), bias_value, dtype=float)\n",
    "\n",
    "    # Linear transform (belum ReLU)\n",
    "    Z = np.dot(X, W1) + b1  # (8×9) · (9×18) + (1×18) -> (8×18)\n",
    "\n",
    "    return Z, W1, b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0128203",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(formatter={'float': lambda x: f\"{x:0.3f}\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "754519ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z shape: (8, 18)\n",
      "W1 shape: (9, 18)\n",
      "W1:\n",
      " [[-0.118 0.425 0.219 0.093 -0.324 -0.324 -0.417 0.345 0.095 0.196 -0.452\n",
      "  0.443 0.313 -0.271 -0.300 -0.298 -0.185 0.023]\n",
      " [-0.064 -0.197 0.105 -0.340 -0.196 -0.126 -0.041 0.269 -0.283 0.013\n",
      "  0.087 -0.428 0.101 -0.311 -0.410 0.423 0.439 0.291]\n",
      " [-0.184 -0.379 0.174 -0.056 -0.356 -0.004 -0.439 0.386 -0.227 0.153\n",
      "  -0.177 0.019 0.044 -0.297 0.443 0.259 0.414 0.372]\n",
      " [0.092 0.398 -0.388 -0.287 -0.429 -0.165 -0.105 -0.216 0.310 -0.135\n",
      "  -0.206 0.040 -0.339 0.285 -0.401 0.459 0.257 -0.284]\n",
      " [-0.466 0.297 0.195 0.216 0.256 -0.402 -0.133 -0.362 0.342 0.116 -0.159\n",
      "  -0.411 -0.178 -0.165 0.216 0.130 0.365 -0.026]\n",
      " [-0.359 0.201 0.246 0.058 0.256 -0.006 0.021 -0.068 -0.447 -0.370 -0.442\n",
      "  0.129 -0.175 0.008 0.384 -0.236 -0.085 0.241]\n",
      " [-0.256 -0.399 -0.198 -0.319 0.405 0.290 0.126 0.350 0.286 -0.295 0.370\n",
      "  0.037 0.290 0.373 -0.172 -0.368 -0.257 -0.069]\n",
      " [0.300 0.340 -0.465 0.010 -0.078 -0.262 -0.358 -0.153 0.418 -0.167 0.018\n",
      "  0.191 -0.129 0.445 0.436 -0.234 -0.003 -0.188]\n",
      " [-0.203 -0.437 0.103 0.003 -0.423 -0.209 0.385 -0.245 -0.335 -0.010\n",
      "  0.458 -0.243 0.162 0.247 -0.247 0.215 -0.125 0.125]]\n",
      "b1 shape: (18,)\n",
      "\n",
      "Preview output Z (belum ReLU):\n",
      " [[1.158 -0.073 1.070 -0.107 -0.450 1.173 1.176 1.779 0.559 1.670 1.512\n",
      "  -0.024 1.218 0.081 -1.098 3.157 2.311 1.331]\n",
      " [1.311 0.132 0.206 -0.352 0.067 1.713 1.604 1.395 1.153 0.848 1.697\n",
      "  0.591 0.869 1.411 -0.986 2.562 1.537 0.637]\n",
      " [1.625 0.412 -0.049 -0.323 -0.009 1.613 1.225 1.169 1.175 0.770 1.420\n",
      "  0.518 0.370 1.422 -0.262 2.848 2.039 0.681]\n",
      " [1.527 -0.474 0.419 -0.434 -0.166 1.490 1.844 1.683 0.735 1.119 2.476\n",
      "  0.089 1.502 1.136 -1.501 2.600 1.501 0.984]\n",
      " [1.738 0.542 0.716 -0.090 -0.715 0.829 0.913 1.645 0.788 1.668 1.415\n",
      "  0.177 1.152 0.233 -1.194 3.035 2.254 1.119]\n",
      " [1.481 0.959 0.497 0.107 -0.283 1.654 0.953 1.542 0.473 0.678 0.375\n",
      "  1.807 0.604 1.218 0.013 1.942 1.140 0.898]\n",
      " [1.300 0.778 0.829 -0.001 -0.576 1.144 1.699 1.189 0.390 1.089 1.121\n",
      "  0.798 0.987 0.891 -1.563 2.601 1.280 0.854]\n",
      " [1.144 2.639 1.143 0.723 0.187 0.238 0.631 0.987 1.611 1.620 -0.054\n",
      "  0.912 0.842 0.048 -1.187 1.943 1.596 0.485]]\n"
     ]
    }
   ],
   "source": [
    "X_attention_norm = np.array([\n",
    "    [-0.177,  1.595,  0.668,  1.240, -0.415, -1.402, -0.094, -1.511,  0.096],\n",
    "    [-0.653,  0.504,  0.260,  2.092, -0.867, -0.898,  0.794, -1.297,  0.066],\n",
    "    [-1.178,  0.644,  0.613,  2.217, -0.855, -0.710,  0.286, -0.699, -0.318],\n",
    "    [-0.449,  1.646, -0.167,  1.091, -1.074, -1.436,  0.650, -0.904,  0.645],\n",
    "    [ 0.098,  1.995,  0.161,  1.197, -0.681, -1.522, -0.541, -0.692, -0.015],\n",
    "    [-0.008, -0.261,  0.751,  2.098, -1.668,  0.365, -0.040, -0.995, -0.243],\n",
    "    [ 0.285,  0.819, -0.374,  1.975, -1.102, -0.417, -0.226, -1.554,  0.593],\n",
    "    [ 1.392,  0.977, -1.087,  1.440,  0.465, -0.666, -0.712, -1.060, -0.749]\n",
    "], dtype=float)\n",
    "\n",
    "# Jalankan layer FFNN pertama\n",
    "Z, W1, b1 = ffnn_layer1(X_attention_norm, out_dim=18, bias_value=1.0, seed=42)\n",
    "\n",
    "print(\"Z shape:\", Z.shape)\n",
    "print(\"W1 shape:\", W1.shape)\n",
    "print(\"W1:\\n\", np.round(W1, 4))\n",
    "print(\"b1 shape:\", b1.shape)\n",
    "print(\"\\nPreview output Z (belum ReLU):\\n\", np.round(Z, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c05f727",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.158, 0.000, 1.070, 0.000, 0.000, 1.173, 1.176, 1.779, 0.559,\n",
       "        1.670, 1.512, 0.000, 1.218, 0.081, 0.000, 3.157, 2.311, 1.331],\n",
       "       [1.311, 0.132, 0.206, 0.000, 0.067, 1.713, 1.604, 1.395, 1.153,\n",
       "        0.848, 1.697, 0.591, 0.869, 1.411, 0.000, 2.562, 1.537, 0.637],\n",
       "       [1.625, 0.412, 0.000, 0.000, 0.000, 1.613, 1.225, 1.169, 1.175,\n",
       "        0.770, 1.420, 0.518, 0.370, 1.422, 0.000, 2.848, 2.039, 0.681],\n",
       "       [1.527, 0.000, 0.419, 0.000, 0.000, 1.490, 1.844, 1.683, 0.735,\n",
       "        1.119, 2.476, 0.089, 1.502, 1.136, 0.000, 2.600, 1.501, 0.984],\n",
       "       [1.738, 0.542, 0.716, 0.000, 0.000, 0.829, 0.913, 1.645, 0.788,\n",
       "        1.668, 1.415, 0.177, 1.152, 0.233, 0.000, 3.035, 2.254, 1.119],\n",
       "       [1.481, 0.959, 0.497, 0.107, 0.000, 1.654, 0.953, 1.542, 0.473,\n",
       "        0.678, 0.375, 1.807, 0.604, 1.218, 0.013, 1.942, 1.140, 0.898],\n",
       "       [1.300, 0.778, 0.828, 0.000, 0.000, 1.144, 1.699, 1.189, 0.390,\n",
       "        1.089, 1.121, 0.798, 0.987, 0.891, 0.000, 2.601, 1.280, 0.854],\n",
       "       [1.144, 2.639, 1.143, 0.723, 0.187, 0.238, 0.631, 0.987, 1.611,\n",
       "        1.620, 0.000, 0.912, 0.842, 0.048, 0.000, 1.943, 1.596, 0.485]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z1_relu = np.maximum(0, Z)\n",
    "Z1_relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68292488",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 18)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z1_relu.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9b839c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W2 shape: (18, 9)\n",
      "b2 shape: (9,)\n",
      "Z2 shape: (8, 9)\n",
      "W2:\n",
      " [[0.126 0.034 -0.386 0.316 -0.169 -0.296 -0.433 0.086 0.167]\n",
      " [-0.456 0.011 -0.258 0.137 -0.307 0.180 -0.107 0.412 -0.342]\n",
      " [-0.150 -0.364 0.400 0.356 -0.228 0.151 0.299 0.052 0.028]\n",
      " [-0.243 -0.384 0.374 0.378 0.126 -0.152 -0.142 0.213 0.374]\n",
      " [0.365 0.264 0.134 -0.392 -0.319 0.376 0.100 -0.463 -0.376]\n",
      " [0.154 -0.467 -0.320 0.046 0.181 0.143 -0.260 0.200 -0.248]\n",
      " [-0.165 0.232 0.141 0.329 0.149 0.064 -0.383 -0.125 -0.221]\n",
      " [-0.241 0.446 -0.101 0.370 0.124 0.278 0.003 0.072 -0.007]\n",
      " [-0.287 0.210 -0.207 -0.449 0.137 -0.304 0.415 0.428 0.391]\n",
      " [-0.122 -0.457 0.404 -0.068 0.440 0.437 0.333 -0.194 -0.108]\n",
      " [0.331 -0.173 -0.312 0.054 0.411 0.185 0.066 -0.380 0.108]\n",
      " [0.462 -0.339 0.017 0.356 0.227 0.186 0.191 -0.133 -0.195]\n",
      " [0.292 0.292 0.346 0.390 0.011 0.001 0.281 0.141 0.190]\n",
      " [0.279 0.368 -0.153 -0.117 -0.383 0.074 -0.438 -0.032 0.040]\n",
      " [-0.201 0.086 -0.443 -0.436 0.304 -0.132 -0.352 0.021 0.255]\n",
      " [-0.268 0.116 -0.391 -0.423 0.030 0.038 0.130 0.213 0.449]\n",
      " [0.015 -0.167 0.278 -0.216 -0.058 -0.397 -0.448 0.436 0.317]\n",
      " [0.185 -0.086 -0.308 -0.324 -0.235 0.046 0.202 0.151 -0.207]]\n",
      "\n",
      "Preview Z2 (tanpa residual & layer norm):\n",
      " [[0.492 0.514 0.089 0.763 2.229 1.669 0.907 2.765 2.969]\n",
      " [1.263 1.303 -1.010 0.880 2.060 1.494 -0.184 2.386 2.520]\n",
      " [0.958 1.148 -1.404 0.274 1.685 1.002 -0.620 2.915 2.791]\n",
      " [1.425 1.391 -0.834 1.398 2.370 1.786 0.022 2.021 2.664]\n",
      " [0.394 0.764 -0.295 0.787 1.949 1.401 0.685 2.988 3.026]\n",
      " [1.292 0.670 -0.741 1.910 1.239 1.830 -0.054 2.676 1.357]\n",
      " [0.806 0.893 -0.312 1.587 1.605 1.895 0.232 2.355 1.927]\n",
      " [-1.031 0.369 0.701 1.405 1.008 1.474 1.413 3.908 2.033]]\n"
     ]
    }
   ],
   "source": [
    "hidden_dim = Z1_relu.shape[1]                \n",
    "D_out      = X_attention_norm.shape[1]       \n",
    "\n",
    "# Inisialisasi W2, b2 dengan Xavier Uniform & bias=1\n",
    "W2 = xavier_uniform((hidden_dim, D_out))\n",
    "b2 = np.full((D_out,), 1.0, dtype=float)\n",
    "\n",
    "# Linear layer-2 (tanpa aktivasi)\n",
    "Z2 = Z1_relu @ W2 + b2    # shape: (N, D_out)\n",
    "\n",
    "print(\"W2 shape:\", W2.shape)   # (hidden_dim, D_out)\n",
    "print(\"b2 shape:\", b2.shape)   # (D_out,)\n",
    "print(\"Z2 shape:\", Z2.shape)   # (N, D_out)\n",
    "print(\"W2:\\n\", np.round(W2, 4))\n",
    "print(\"\\nPreview Z2 (tanpa residual & layer norm):\\n\", np.round(Z2, 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a751bf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.315, 2.109, 0.757, 2.003, 1.814, 0.267, 0.813, 1.254, 3.065],\n",
       "       [0.610, 1.807, -0.750, 2.972, 1.193, 0.596, 0.610, 1.089, 2.586],\n",
       "       [-0.220, 1.792, -0.791, 2.490, 0.830, 0.292, -0.334, 2.216, 2.473],\n",
       "       [0.976, 3.037, -1.000, 2.489, 1.296, 0.351, 0.672, 1.117, 3.309],\n",
       "       [0.492, 2.759, -0.134, 1.984, 1.268, -0.121, 0.144, 2.296, 3.011],\n",
       "       [1.284, 0.410, 0.010, 4.008, -0.429, 2.195, -0.094, 1.681, 1.114],\n",
       "       [1.091, 1.712, -0.686, 3.562, 0.503, 1.478, 0.006, 0.801, 2.520],\n",
       "       [0.361, 1.346, -0.386, 2.845, 1.473, 0.807, 0.701, 2.848, 1.284]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z2_out = X_attention_norm + Z2\n",
    "Z2_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5883e24f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.200, 0.826, -0.702, 0.707, 0.494, -1.255, -0.638, -0.140,\n",
       "        1.908],\n",
       "       [-0.542, 0.576, -1.813, 1.665, 0.002, -0.555, -0.542, -0.095,\n",
       "        1.304],\n",
       "       [-0.973, 0.670, -1.440, 1.240, -0.116, -0.555, -1.066, 1.016,\n",
       "        1.226],\n",
       "       [-0.296, 1.291, -1.819, 0.870, -0.050, -0.778, -0.530, -0.188,\n",
       "        1.501],\n",
       "       [-0.683, 1.234, -1.213, 0.578, -0.027, -1.201, -0.978, 0.843,\n",
       "        1.447],\n",
       "       [0.117, -0.551, -0.856, 2.196, -1.191, 0.812, -0.935, 0.420,\n",
       "        -0.013],\n",
       "       [-0.107, 0.404, -1.569, 1.926, -0.591, 0.212, -0.999, -0.346,\n",
       "        1.069],\n",
       "       [-0.886, 0.093, -1.629, 1.581, 0.219, -0.443, -0.548, 1.584,\n",
       "        0.030]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def layer_norm(x, eps=1e-5):\n",
    "    # normalisasi per token (per baris)\n",
    "    mu  = x.mean(axis=1, keepdims=True)\n",
    "    var = x.var(axis=1, keepdims=True)\n",
    "    return (x - mu) / np.sqrt(var + eps), mu.squeeze(), np.sqrt(var + eps).squeeze()\n",
    "\n",
    "Z2_norm, Z_row_mean, Z_row_std = layer_norm(Z2_out)\n",
    "Z2_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b6c0fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z1 mean: [1.377 1.191 0.972 1.361 1.300 1.131 1.221 1.253]\n",
      "Z1 std : [0.885 1.070 1.225 1.298 1.182 1.310 1.215 1.007]\n"
     ]
    }
   ],
   "source": [
    "print(\"Z1 mean:\", Z_row_mean)\n",
    "print(\"Z1 std :\", Z_row_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1a16a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W_linear shape: (9, 9)\n",
      "Y_linear: (8, 9)\n",
      "Preview Y_linear:\n",
      " [[1.729 1.044 1.752 1.690 0.344 2.493 1.307 1.145 1.919]\n",
      " [2.483 1.251 1.117 0.565 0.392 1.841 1.198 1.515 1.548]\n",
      " [1.278 1.417 1.769 1.289 0.228 1.587 1.278 0.751 2.493]\n",
      " [2.209 0.847 1.209 1.393 0.252 2.414 0.740 1.158 1.370]\n",
      " [1.321 1.285 2.038 2.211 0.098 2.203 1.023 0.459 2.427]\n",
      " [1.781 1.575 0.708 -0.836 0.476 -0.490 0.654 1.388 1.558]\n",
      " [2.329 1.100 0.751 -0.252 0.317 0.874 0.514 1.640 1.158]\n",
      " [1.174 1.956 1.519 0.922 0.872 0.978 2.063 0.756 2.713]]\n"
     ]
    }
   ],
   "source": [
    "N, D = Z2_norm.shape\n",
    "M = D\n",
    "\n",
    "W_linear = xavier_uniform((D, M))\n",
    "b_linear = np.ones((M,), dtype=float)\n",
    "\n",
    "y_linear = Z2_norm @ W_linear + b_linear\n",
    "\n",
    "print(\"W_linear shape:\", W_linear.shape)\n",
    "print(\"Y_linear:\", y_linear.shape)\n",
    "print(\"Preview Y_linear:\\n\", np.round(y_linear, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "feeac757",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.525, 0.275, 0.063, 0.129, -0.093, -0.291, -0.166, 0.298,\n",
       "        -0.561],\n",
       "       [-0.443, -0.524, -0.530, 0.410, 0.235, -0.030, -0.464, -0.010,\n",
       "        -0.031],\n",
       "       [-0.377, -0.076, -0.117, 0.134, 0.156, -0.525, -0.145, 0.145,\n",
       "        0.004],\n",
       "       [0.412, 0.183, -0.389, -0.496, 0.164, -0.547, 0.099, 0.508, 0.087],\n",
       "       [-0.129, 0.165, -0.048, 0.053, 0.510, -0.132, 0.533, 0.468,\n",
       "        -0.351],\n",
       "       [-0.497, -0.461, -0.556, -0.468, 0.211, -0.495, -0.209, 0.398,\n",
       "        -0.550],\n",
       "       [0.363, -0.252, -0.441, 0.227, 0.149, 0.436, 0.271, 0.350, -0.252],\n",
       "       [-0.372, 0.289, 0.354, 0.566, -0.101, -0.148, 0.319, -0.184,\n",
       "        0.497],\n",
       "       [0.414, -0.082, 0.290, 0.294, -0.458, 0.465, 0.006, 0.377, -0.208]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_linear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0d5172",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "577896df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLS shape: (9,)\n",
      "W_cls shape: (9, 9)\n",
      "cls_linear:\n",
      " [2.180 -0.200 1.640 -1.630 -1.740 1.470 -0.020 1.950 -0.720]\n",
      "cls_tanh:\n",
      " [0.970 -0.200 0.930 -0.930 -0.940 0.900 -0.020 0.960 -0.620]\n"
     ]
    }
   ],
   "source": [
    "CLS = y_linear[0]       \n",
    "M   = CLS.shape[0]\n",
    "\n",
    "np.random.seed(77)\n",
    "\n",
    "# Linear untuk [CLS] (Xavier)\n",
    "H_cls = 9\n",
    "W_cls = xavier_uniform((M, H_cls))\n",
    "b_cls = np.ones((H_cls,), dtype=float)\n",
    "\n",
    "cls_linear = CLS @ W_cls + b_cls      \n",
    "cls_tanh   = np.tanh(cls_linear)      \n",
    "\n",
    "print(\"CLS shape:\", CLS.shape)\n",
    "print(\"W_cls shape:\", W_cls.shape)\n",
    "print(\"cls_linear:\\n\", np.round(cls_linear, 2))\n",
    "print(\"cls_tanh:\\n\", np.round(cls_tanh, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "54707b13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.729, 1.044, 1.752, 1.690, 0.344, 2.493, 1.307, 1.145, 1.919])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "360c3625",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.484, 0.164, 0.293, -0.416, -0.477, 0.333, -0.201, 0.047,\n",
       "        -0.300],\n",
       "       [0.052, -0.115, 0.248, 0.389, 0.102, -0.235, -0.253, 0.237,\n",
       "        -0.089],\n",
       "       [-0.511, 0.285, -0.055, -0.374, -0.520, -0.240, -0.500, 0.290,\n",
       "        -0.504],\n",
       "       [-0.079, -0.157, -0.402, 0.054, -0.065, -0.536, 0.373, -0.262,\n",
       "        -0.382],\n",
       "       [0.167, -0.453, -0.169, -0.132, -0.063, 0.551, 0.265, -0.217,\n",
       "        0.456],\n",
       "       [0.327, -0.275, -0.220, -0.428, -0.090, 0.508, -0.154, -0.075,\n",
       "        0.482],\n",
       "       [0.516, -0.283, 0.242, -0.520, -0.422, 0.008, 0.103, -0.200,\n",
       "        -0.410],\n",
       "       [-0.280, 0.413, 0.212, 0.576, -0.208, -0.054, 0.424, 0.160,\n",
       "        -0.194],\n",
       "       [0.048, -0.448, 0.365, -0.322, 0.017, 0.030, -0.257, 0.467,\n",
       "        -0.092]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "48f30296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W_clf shape: (9, 2)\n",
      "logits: [0.253 -0.328]\n",
      "softmax probs (Class A, Class B): [0.641 0.358]\n"
     ]
    }
   ],
   "source": [
    "feat = cls_tanh                \n",
    "F    = feat.shape[0]\n",
    "num_labels = 2\n",
    "\n",
    "np.random.seed(1313)\n",
    "\n",
    "# Bobot classifier (Xavier) dan bias=1 \n",
    "W_clf = xavier_uniform((F, num_labels))\n",
    "b_clf = np.ones((num_labels,), dtype=float)\n",
    "\n",
    "logits = feat @ W_clf + b_clf      # (2,)\n",
    "# Softmax\n",
    "logits_shift = logits - logits.max()\n",
    "probs = np.exp(logits_shift) / np.exp(logits_shift).sum()\n",
    "\n",
    "print(\"W_clf shape:\", W_clf.shape)\n",
    "print(\"logits:\", np.round(logits, 3))\n",
    "print(\"softmax probs (Class A, Class B):\", np.round(probs, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "775069ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.727, -0.693],\n",
       "       [0.518, 0.713],\n",
       "       [-0.437, -0.004],\n",
       "       [-0.328, 0.569],\n",
       "       [0.229, 0.489],\n",
       "       [-0.649, 0.133],\n",
       "       [0.671, 0.721],\n",
       "       [-0.201, 0.468],\n",
       "       [0.398, 0.123]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_clf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
